# ğŸ¤– End-to-End MLOps Pipeline â€“ Iris Classifier Project - Group 64

This project demonstrates a complete **End-to-End MLOps workflow** using the Iris dataset. It includes model training, hyperparameter tuning, experiment tracking, serving via FastAPI, containerization with Docker, CI/CD with GitHub Actions, and deployment to AWS EC2 with logging and monitoring.

---

## ğŸ“Œ Objective 

Automate and scale the lifecycle of an ML model from experimentation to production deployment, using real-world MLOps tools and cloud infrastructure.

---

## ğŸ§° Tech Stack

- **Data & Modeling**: scikit-learn, pandas, Optuna
- **Experiment Tracking**: MLflow
- **Model Serving**: FastAPI
- **Containerization**: Docker
- **CI/CD**: GitHub Actions
- **Deployment**: AWS EC2 + ECR
- **Logging**: Amazon CloudWatch
- **Monitoring**: Prometheus & Grafana (local setup)
- **A/B Testing**: Supported locally

---

## ğŸ—‚ï¸ Folder Structure

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ baseline.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ model_builder.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ model_config.yaml
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ predict.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .github/workflows/ci-cd.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸ§ª Model Training (with MLflow + Optuna)

```bash
python src/train_model.py
```

MLflow logs are saved under `mlruns/`. The best model is saved to `models/` or registered in MLflow.

---

## ğŸŒ Run Locally with FastAPI

```bash
uvicorn app.main:app --reload
```

- Endpoint: `http://localhost:8000/predict`
- Input:
```json
{
  "sepal_length": 5.1,
  "sepal_width": 3.5,
  "petal_length": 1.4,
  "petal_width": 0.2
}
```
- Output:
```json
{
  "prediction": "setosa"
}
```

---

## ğŸ³ Docker Usage

```bash
# Build Docker image
docker build -t iris-classifier-app .

# Run container
docker run -d -p 8000:8000 iris-classifier-app
```

---

## ğŸš€ CI/CD & EC2 Deployment

- GitHub Actions workflow builds the image and pushes to AWS ECR
- SSHs into EC2 instance
- Pulls the latest image and runs the container
- Secrets are managed using GitHub Repository Settings

---

## ğŸ“Š Logging & Monitoring

- âœ… Logs are streamed to **Amazon CloudWatch**
- âš™ï¸ Prometheus + Grafana are set up locally (to be ported to EC2)

---

## ğŸ” A/B Testing

- `baseline.py` runs a simpler baseline model
- Run both models and expose endpoints `/predict-a` and `/predict-b`

---

## ğŸ§± Architecture Diagram

```
User â”€â–¶ FastAPI â”€â–¶ Docker â”€â–¶ Model â”€â–¶ MLflow
           â”‚           â”‚         â”‚
           â–¼           â–¼         â–¼
     GitHub Actions â†’ AWS EC2 â†’ CloudWatch
```

---

## â• Extending to a New Dataset

To use a new dataset:
1. Replace preprocessing logic in your notebook or `preprocess.py`
2. Update `data_loader.py` to match new schema
3. Adjust `model_config.yaml` with new features and target

Optional: Parameterize dataset name for multi-dataset support.

---

## âœ… Completion Checklist

| Task                           | Status     |
|--------------------------------|------------|
| Data Preprocessing             | âœ… Completed |
| Model Training                 | âœ… Completed |
| MLflow Integration             | âœ… Completed |
| Hyperparameter Tuning (Optuna)| âœ… Completed |
| FastAPI API                    | âœ… Completed |
| Dockerization                  | âœ… Completed |
| CI/CD with GitHub Actions      | âœ… Completed |
| EC2 Deployment                 | âœ… Completed |
| CloudWatch Logging             | âœ… Completed |
| Monitoring (Grafana/Prometheus)| ğŸ”„ Local Testing |
| A/B Testing                    | ğŸ”„ Local Setup |
| Final README                   | âœ… You're here! |

---

## ğŸ§  Author

**Shubh** â€“ Building hands-on expertise in full MLOps workflows for production-ready machine learning systems.
